{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 13:18:26.472765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gc\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# conda install -c conda-forge wordcloud\n",
    "\n",
    "# import spacy\n",
    "# from collections import Counter, defaultdict\n",
    "# import en_core_web_sm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D, Embedding, add, concatenate, Concatenate, Input\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPool1D\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jit(\"gpu\")\n",
    "train_data = pd.read_csv('train_1.csv')\n",
    "# train_data = pd.read_csv('train.csv.zip')\n",
    "# test_data = pd.read_csv('test.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Explanation\\nWhy the edits made under my usern...\n",
       "1     D'aww! He matches this background colour I'm s...\n",
       "2     Hey man, I'm really not trying to edit war. It...\n",
       "3     \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4     You, sir, are my hero. Any chance you remember...\n",
       "5     \"\\n\\nCongratulations from me as well, use the ...\n",
       "6          COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
       "7     Your vandalism to the Matt Shirvington article...\n",
       "8     Sorry if the word 'nonsense' was offensive to ...\n",
       "9     alignment on this subject and which are contra...\n",
       "10    \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...\n",
       "11    bbq \\n\\nbe a man and lets discuss it-maybe ove...\n",
       "12    Hey... what is it..\\n@ | talk .\\nWhat is it......\n",
       "13    Before you start throwing accusations and warn...\n",
       "14    Oh, and the girl above started her arguments w...\n",
       "15    \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...\n",
       "16    Bye! \\n\\nDon't look, come or think of comming ...\n",
       "17     REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski\n",
       "18    The Mitsurugi point made no sense - why not ar...\n",
       "19    Don't mean to bother you \\n\\nI see that you're...\n",
       "20    \"\\n\\n Regarding your recent edits \\n\\nOnce aga...\n",
       "21    \"\\nGood to know. About me, yeah, I'm studying ...\n",
       "22    \"\\n\\n Snowflakes are NOT always symmetrical! \\...\n",
       "23    \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...\n",
       "24    \"\\n\\nRe-considering 1st paragraph edit?\\nI don...\n",
       "25    Radial symmetry \\n\\nSeveral now extinct lineag...\n",
       "26    There's no need to apologize. A Wikipedia arti...\n",
       "27    Yes, because the mother of the child in the ca...\n",
       "28    \"\\nOk. But it will take a bit of work but I ca...\n",
       "29    \"== A barnstar for you! ==\\n\\n  The Real Life ...\n",
       "30    How could I post before the block expires?  Th...\n",
       "31    Not sure about a heading of 'Fight for Freedom...\n",
       "32    Praise \\n\\nlooked at this article about 6 mont...\n",
       "33    I was able to post the above list so quickly b...\n",
       "34    \"\\nWell, not \"\"before the process\"\" but \"\"befo...\n",
       "35    \"\\n\\nNot at all, you are making a straw man ar...\n",
       "36    \"\\n\\n \"\"Mainland Asia\"\" includes \"\"the lower b...\n",
       "37    pretty much everyone from warren county/surrou...\n",
       "38    Hi Explicit, can you block O Fenian for edit-w...\n",
       "39    Notability of Rurika Kasuga\\nA tag has been pl...\n",
       "40    \"\\n Sure, but the lead must briefly summarize ...\n",
       "41    TFD \\n\\nI think we just eced. I think we respo...\n",
       "42    You are gay or antisemmitian? \\n\\nArchangel WH...\n",
       "43             FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
       "44    I'm Sorry \\n\\nI'm sorry I screwed around with ...\n",
       "45    I don't believe the Lisak criticism present th...\n",
       "46    You had a point, and it's now ammended with ap...\n",
       "47    In other words, you're too lazy to actually po...\n",
       "48    \"\\nAs for your claims of \"\"stalking\"\", that is...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"comment_text\"].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "df = pd.DataFrame()\n",
    "#Lemmatize Words\n",
    "import nltk\n",
    "def get_pos_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "APPO = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"\n",
    "}\n",
    "\n",
    "REPLACE_URLS = re.compile(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+')\n",
    "REPLACE_HASH = re.compile(r'#(\\w+)')\n",
    "REPLACE_AT = re.compile(r'@(\\w+)')\n",
    "REPLACE_HTML_TAGS = re.compile(r'<[^>]+>')\n",
    "REPLACE_DIGITS = re.compile(r'\\d+')\n",
    "#REPLACE_PUNCTUATION = re.compile(r'!\\\"#+$%&\\)*,-./:;<=>?@[\\\\]^_`{|}~\\t\\(\\\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—')     #[,!@\\'\\\"?\\.$%_&#*+-:;]\")       #[!\\\"#$%&\\'()*+,-\\./:;<=>?@[\\\\]^_`{|}~]\")\n",
    "REPLACE_PUNCTUATION = regex.compile('[\\p{C}|\\p{M}|\\p{P}|\\p{S}|\\p{Z}]+', regex.UNICODE)\n",
    "LEAKY_FEATURE = re.compile(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\") \n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "sentences = [] #for Word2Vec model\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_HTML_TAGS.sub(' ', text)\n",
    "    \n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    \n",
    "    text = REPLACE_URLS.sub('', text)\n",
    "    #text = REPLACE_HASH.sub('', text)\n",
    "    text = REPLACE_AT.sub('', text)\n",
    "    text = REPLACE_DIGITS.sub('', text)\n",
    "    text = REPLACE_PUNCTUATION.sub(' ' , text).strip()\n",
    "    text = LEAKY_FEATURE.sub('', text)\n",
    "    \n",
    "    text = [APPO[word] if word in APPO else word for word in text.split()]\n",
    "    \n",
    "    text = \" \".join(lemmatizer.lemmatize(word.strip(), get_pos_tag(pos_tag([word.strip()])[0][1])) for word in text if word not in STOPWORDS)\n",
    "    \n",
    "    #sentences.append(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"comment\"] = train_data[\"comment_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/numanaslam/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     explanation edits make username hardcore metal...\n",
       "1     aww match background colour seemingly stuck th...\n",
       "2     hey man really try edit war guy constantly rem...\n",
       "3     make real suggestion improvement wonder sectio...\n",
       "4                         sir hero chance remember page\n",
       "5                congratulation well use tool well talk\n",
       "6                           cocksucker piss around work\n",
       "7     vandalism matt shirvington article revert plea...\n",
       "8     sorry word nonsense offensive anyway intend wr...\n",
       "9                  alignment subject contrary dulithgow\n",
       "10    fair use rationale image wonju jpg thanks uplo...\n",
       "11                       bbq man let discus maybe phone\n",
       "12    hey talk exclusive group wp taliban good destr...\n",
       "13    start throw accusation warning let review edit...\n",
       "14    oh girl start argument stuck nose belong belie...\n",
       "15    juelz santanas age juelz santana year old come...\n",
       "16              bye look come think comming back tosser\n",
       "17      redirect talk voydan pop georgiev chernodrinski\n",
       "18    mitsurugi point make sense argue include hindi...\n",
       "19    mean bother see write something regard remove ...\n",
       "20    regard recent edits please read wp filmplot ed...\n",
       "21                           good know yeah study deepu\n",
       "22    snowflake always symmetrical geometry state sn...\n",
       "23    signpost september read signpost full single p...\n",
       "24    consider st paragraph edit understand reason r...\n",
       "25    radial symmetry several extinct lineage includ...\n",
       "26    need apologize wikipedia article make reconcil...\n",
       "27    yes mother child case michael jackson study mo...\n",
       "28     ok take bit work quite picture example base duck\n",
       "29               barnstar real life barnstar let u star\n",
       "30    could post block expires funny thing think unc...\n",
       "31                      sure head fight freedom contain\n",
       "32           praise look article month ago much improve\n",
       "33    able post list quickly already text file hard ...\n",
       "34    well process thing subpages rfa list noseptemb...\n",
       "35    make straw man argument never claimed donohue ...\n",
       "36    mainland asia include low basin china yangtze ...\n",
       "37    pretty much everyone warren county surround re...\n",
       "38    hi explicit block fenian edit war giant causew...\n",
       "39    notability rurika kasuga tag place rurika kasu...\n",
       "40    sure lead must briefly summarize armenia histo...\n",
       "41    tfd think eced think respond without see other...\n",
       "42    gay antisemmitian archangel white tiger meow g...\n",
       "43                            fuck filthy mother as dry\n",
       "44    sorry sorry screw around someone talk page bad...\n",
       "45    believe lisak criticism present conforms npv r...\n",
       "46    point ammended appropriate encyclopedic notabi...\n",
       "47    word lazy actually point anything change appro...\n",
       "48    claim stalk absolute rubbish serf aggravate si...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
